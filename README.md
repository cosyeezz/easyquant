# EasyQuant - é«˜æ€§èƒ½é‡åŒ–æ•°æ® ETL ç³»ç»Ÿ

[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)

ä¸€ä¸ªä¸“ä¸ºé‡åŒ–äº¤æ˜“è®¾è®¡çš„é«˜æ€§èƒ½ã€å¯æ‰©å±•çš„ ETL (Extract, Transform, Load) ç³»ç»Ÿã€‚åŸºäº Ray åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶ï¼Œæ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†ã€è‡ªåŠ¨å¹‚ç­‰æ€§ä¿è¯ã€æµå¼æ•°æ®åŠ è½½ç­‰ä¼ä¸šçº§ç‰¹æ€§ã€‚

---

## æ ¸å¿ƒç‰¹æ€§

### ğŸš€ é«˜æ€§èƒ½æ¶æ„
- **å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†**ï¼šåŸºäº Ray å®ç°çœŸæ­£çš„ CPU å¹¶è¡Œï¼ˆç»•è¿‡ Python GILï¼‰
- **åŠ¨æ€æ‰¹å¤„ç†**ï¼šè‡ªé€‚åº”è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼Œå¹³è¡¡è°ƒåº¦å¼€é”€å’Œè´Ÿè½½å‡è¡¡
- **æµå¼æ•°æ®åŠ è½½**ï¼šå†…ç½®ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼ï¼Œé¿å…å†…å­˜æº¢å‡º
- **èƒŒå‹æ§åˆ¶**ï¼šè‡ªåŠ¨é™åˆ¶æœªå®Œæˆä»»åŠ¡æ•°é‡ï¼Œé˜²æ­¢èµ„æºè€—å°½

### ğŸ›¡ï¸ å¯é æ€§ä¿è¯
- **å¹‚ç­‰æ€§æœºåˆ¶**ï¼šåŸºäºæ–‡ä»¶å…ƒæ•°æ®ï¼ˆsize + mtimeï¼‰ï¼Œç¡®ä¿æ•°æ®ä¸é‡å¤å¤„ç†
- **åˆ†å¸ƒå¼é”**ï¼šPostgreSQL åŸå­é”ï¼Œé˜²æ­¢å¹¶å‘å†²çª
- **ç‹¬ç«‹äº‹åŠ¡**ï¼šå•ä¸ªæ•°æ®æºå¤±è´¥ä¸å½±å“å…¶ä»–æ•°æ®æº
- **è‡ªåŠ¨é‡è¯•**ï¼šå¤±è´¥ä»»åŠ¡ä¼šåœ¨ä¸‹æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨é‡è¯•
- **èµ„æºè‡ªåŠ¨æ¸…ç†**ï¼šæ•°æ®åº“è¿æ¥æ± å’Œ Ray é›†ç¾¤çš„æ­£ç¡®é‡Šæ”¾

### ğŸ”§ é«˜æ‰©å±•æ€§
- **æ’æ‹”å¼æ•°æ®æº**ï¼šæ”¯æŒ CSVã€APIã€æ•°æ®åº“ç­‰ä»»æ„æ•°æ®æºï¼ˆé€šè¿‡ `BaseLoader` æŠ½è±¡ï¼‰
- **æ’æ‹”å¼å¤„ç†ç®¡é“**ï¼šé€šè¿‡ `Pipeline` å·¥å‚æ¨¡å¼æ³¨å…¥è‡ªå®šä¹‰å¤„ç†é€»è¾‘
- **å¤„ç†å™¨é“¾å¼ç»„åˆ**ï¼šæ”¯æŒä»»æ„æ•°é‡çš„ `Handler` ä¸²è”æ‰§è¡Œ

---

## ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ç”¨æˆ·å…¥å£                                 â”‚
â”‚                    etl/scripts/run_etl.py                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      è°ƒåº¦å™¨ (Scheduler)                          â”‚
â”‚  - åˆå§‹åŒ– Ray é›†ç¾¤                                                â”‚
â”‚  - å¹‚ç­‰æ€§è¿‡æ»¤ï¼ˆæ‰¹é‡æŸ¥è¯¢æ•°æ®åº“ï¼‰                                     â”‚
â”‚  - åŠ¨æ€æ‰¹å¤„ç†ï¼ˆè‡ªé€‚åº” batch sizeï¼‰                                 â”‚
â”‚  - ä»»åŠ¡åˆ†å‘ï¼ˆè½®è¯¢è°ƒåº¦ + èƒŒå‹æ§åˆ¶ï¼‰                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚
       â–¼                  â–¼                  â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Worker 0â”‚         â”‚Worker 1â”‚   ...   â”‚Worker Nâ”‚  (Ray Actor Pool)
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
        â”‚                  â”‚                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      æ•°æ®åŠ è½½å™¨ (BaseLoader)            â”‚
        â”‚  - æµå¼åŠ è½½æ•°æ®ï¼ˆç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼ï¼‰       â”‚
        â”‚  - è®¡ç®—æ–‡ä»¶å…ƒæ•°æ®ï¼ˆå¿«é€Ÿå“ˆå¸Œï¼‰              â”‚
        â”‚  - è‡ªåŠ¨èƒŒå‹å’Œå†…å­˜ç®¡ç†                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       å¹‚ç­‰æ€§æ£€æŸ¥ (IdempotencyChecker)    â”‚
        â”‚  - acquire_lock() è·å–å¤„ç†é”             â”‚
        â”‚  - mark_completed() æ ‡è®°å®Œæˆ             â”‚
        â”‚  - mark_failed() æ ‡è®°å¤±è´¥                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚       å¤„ç†ç®¡é“ (Pipeline)                â”‚
        â”‚  Handler 1 â†’ Handler 2 â†’ ... â†’ Handler Nâ”‚
        â”‚  (æ•°æ®æ¸…æ´—) (æ•°æ®éªŒè¯)    (æ•°æ®åº“å†™å…¥)     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         PostgreSQL æ•°æ®åº“                â”‚
        â”‚  - etl_metadataï¼ˆå¹‚ç­‰æ€§å…ƒæ•°æ®è¡¨ï¼‰         â”‚
        â”‚  - stock_daily/stock_minuteï¼ˆä¸šåŠ¡æ•°æ®ï¼‰   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚
- Python 3.10+
- PostgreSQL 12+
- æ¨èï¼šå¤šæ ¸ CPUï¼ˆå……åˆ†åˆ©ç”¨å¹¶è¡Œå¤„ç†ï¼‰

### å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### é…ç½®æ•°æ®åº“
åœ¨ `config.py` ä¸­é…ç½®æ•°æ®åº“è¿æ¥ï¼š
```python
DATABASE_URL = "postgresql+asyncpg://user:password@localhost:5432/quantdb"
```

### è¿è¡Œ ETL
```bash
# åŸºæœ¬ç”¨æ³•ï¼šå¤„ç†æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ CSV æ–‡ä»¶
python etl/scripts/run_etl.py --data-dir /path/to/csv_files

# æŒ‡å®š Worker æ•°é‡ï¼ˆé»˜è®¤ä¸º CPU æ ¸å¿ƒæ•°ï¼‰
python etl/scripts/run_etl.py --data-dir /path/to/csv_files --max-workers 8

# å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼ˆè·³è¿‡å¹‚ç­‰æ€§æ£€æŸ¥ï¼‰
python etl/scripts/run_etl.py --data-dir /path/to/csv_files --force
```

---

## æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. è°ƒåº¦å™¨ (Scheduler)

**ä½ç½®ï¼š** `etl/scheduler.py`

**èŒè´£ï¼š**
- åˆå§‹åŒ– Ray åˆ†å¸ƒå¼é›†ç¾¤
- æ‰§è¡Œå¹‚ç­‰æ€§è¿‡æ»¤ï¼ˆè·³è¿‡å·²å¤„ç†çš„æ•°æ®æºï¼‰
- åŠ¨æ€è®¡ç®—æ‰¹æ¬¡å¤§å°ï¼ˆå…¬å¼ï¼š`batch_size = ceil(æ€»ä»»åŠ¡æ•° / (Workeræ•° * 4))`ï¼‰
- è½®è¯¢åˆ†å‘ä»»åŠ¡åˆ° Worker æ± 
- èƒŒå‹æ§åˆ¶ï¼ˆé™åˆ¶æœªå®Œæˆä»»åŠ¡æ•°é‡ â‰¤ `max_workers * 2`ï¼‰

**å¹‚ç­‰æ€§è¿‡æ»¤æµç¨‹ï¼š**
1. å¹¶è¡Œè®¡ç®—æ‰€æœ‰æ•°æ®æºçš„å…ƒæ•°æ®ï¼ˆ`identifier` + `content_hash`ï¼‰
2. æ‰¹é‡æŸ¥è¯¢æ•°æ®åº“ä¸­çš„å¤„ç†è®°å½•ï¼ˆå•æ¬¡ SQL æŸ¥è¯¢ï¼‰
3. è¿‡æ»¤è§„åˆ™ï¼š
   - æ–°æ•°æ®æº â†’ åŠ å…¥å¤„ç†é˜Ÿåˆ—
   - æ­£åœ¨å¤„ç†ä¸­ (`PROCESSING`) â†’ è·³è¿‡
   - å†…å®¹å·²æ›´æ–°ï¼ˆå“ˆå¸Œä¸åŒï¼‰ â†’ åŠ å…¥å¤„ç†é˜Ÿåˆ—
   - å¤±è´¥æˆ–å¾…å¤„ç† (`FAILED`/`PENDING`) â†’ åŠ å…¥å¤„ç†é˜Ÿåˆ—
   - å·²å®Œæˆä¸”å†…å®¹æœªå˜ (`COMPLETED`) â†’ è·³è¿‡

---

### 2. Worker æ‰§è¡Œå™¨ (PipelineExecutor)

**ä½ç½®ï¼š** `etl/processing/executor.py`

**èŒè´£ï¼š**
- ç‹¬ç«‹è¿›ç¨‹ä¸­çš„ä»»åŠ¡æ‰§è¡Œå™¨ï¼ˆRay Actorï¼‰
- æ¯ä¸ª Worker æ‹¥æœ‰ç‹¬ç«‹çš„æ•°æ®åº“è¿æ¥æ± 
- æ¯ä¸ªæ•°æ®æºä½¿ç”¨ç‹¬ç«‹äº‹åŠ¡ï¼ˆé¿å…æ‰¹æ¬¡å¤±è´¥å½±å“å…¨éƒ¨æ•°æ®ï¼‰

**æ‰§è¡Œæµç¨‹ï¼š**
```python
async def process_item(self, batch: List[Any]):
    async for source, data in self.loader.stream(sources=batch):
        async with session:
            # 1. è·å–å¤„ç†é”ï¼ˆåŸå­æ“ä½œï¼‰
            locked = await checker.acquire_lock(identifier, content_hash)
            if not locked:
                continue  # è¢«å…¶ä»– Worker é”å®šï¼Œè·³è¿‡

            # 2. è¿è¡Œ Pipeline å¤„ç†æ•°æ®
            result = await pipeline.run(data)

            # 3. æ ‡è®°ä¸ºå·²å®Œæˆ
            await checker.mark_completed(identifier)
            await session.commit()
```

---

### 3. æ•°æ®åŠ è½½å™¨ (BaseLoader)

**ä½ç½®ï¼š** `etl/data_loader/base.py`

**å†…ç½®ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼ï¼š**
- **ç”Ÿäº§è€…** (`_producer`)ï¼šå¹¶è¡ŒåŠ è½½æ‰€æœ‰æ•°æ®æºï¼Œæ”¾å…¥å¼‚æ­¥é˜Ÿåˆ—
- **æ¶ˆè´¹è€…** (`stream`)ï¼šå¼‚æ­¥ç”Ÿæˆå™¨ï¼Œé€ä¸ª yield `(source, DataFrame)`
- **è‡ªåŠ¨èƒŒå‹**ï¼šé˜Ÿåˆ—æ»¡æ—¶ï¼Œç”Ÿäº§è€…è‡ªåŠ¨æš‚åœ

**å­ç±»éœ€å®ç°çš„æŠ½è±¡æ–¹æ³•ï¼š**
```python
class CustomLoader(BaseLoader):
    async def _get_sources(self) -> List[Any]:
        """è¿”å›æ‰€æœ‰æ•°æ®æºæ ‡è¯†ï¼ˆå¦‚æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼‰"""
        pass

    async def _load_one_source(self, source: Any) -> pd.DataFrame:
        """åŠ è½½å•ä¸ªæ•°æ®æºï¼Œè¿”å› DataFrame"""
        pass

    async def get_source_metadata(self, source: Any) -> Tuple[str, str]:
        """è¿”å› (identifier, content_hash) ç”¨äºå¹‚ç­‰æ€§æ£€æŸ¥"""
        pass
```

**CSV åŠ è½½å™¨ç¤ºä¾‹ï¼š** `etl/data_loader/csv_loader.py`

---

### 4. å¤„ç†ç®¡é“ (Pipeline)

**ä½ç½®ï¼š** `etl/processing/pipeline.py`

**èŒè´£ï¼š** ä¸²è”å¤šä¸ª `Handler`ï¼Œä¾æ¬¡å¤„ç†æ•°æ®

```python
# è‡ªå®šä¹‰å¤„ç†å™¨
class DataCleaningHandler(BaseHandler):
    async def handle(self, df: pd.DataFrame) -> pd.DataFrame:
        return df.dropna()

class DataValidationHandler(BaseHandler):
    async def handle(self, df: pd.DataFrame) -> pd.DataFrame:
        return df[df['price'] > 0]

class DatabaseInsertHandler(BaseHandler):
    async def handle(self, df: pd.DataFrame) -> pd.DataFrame:
        await bulk_insert_df(df, 'stock_daily')
        return df

# åˆ›å»º Pipeline
pipeline = Pipeline([
    DataCleaningHandler(),
    DataValidationHandler(),
    DatabaseInsertHandler()
])
```

---

### 5. å¹‚ç­‰æ€§æœºåˆ¶ (IdempotencyChecker)

**ä½ç½®ï¼š** `etl/storage/idempotency.py`

**æ ¸å¿ƒè¡¨ï¼š** `etl_metadata`
```sql
CREATE TABLE etl_metadata (
    id SERIAL PRIMARY KEY,
    source_identifier VARCHAR UNIQUE NOT NULL,  -- æ•°æ®æºå”¯ä¸€æ ‡è¯†ï¼ˆå¦‚æ–‡ä»¶è·¯å¾„ï¼‰
    source_hash VARCHAR NOT NULL,                -- å†…å®¹å“ˆå¸Œï¼ˆsize:mtimeï¼‰
    status VARCHAR NOT NULL,                      -- pending/processing/completed/failed
    processed_at TIMESTAMP DEFAULT NOW()
);
```

**åˆ†å¸ƒå¼é”å®ç°ï¼š**
```python
async def acquire_lock(self, identifier: str, content_hash: str) -> bool:
    stmt = insert(ETLMetadata).values(
        source_identifier=identifier,
        source_hash=content_hash,
        status=ProcessingStatus.PROCESSING
    ).on_conflict_do_update(
        index_elements=['source_identifier'],
        set_={'status': ProcessingStatus.PROCESSING},
        where=(ETLMetadata.status != ProcessingStatus.PROCESSING)  # åªæ›´æ–°æœªé”å®šçš„è®°å½•
    )
    result = await session.execute(stmt)
    return result.rowcount > 0  # rowcount=0 è¡¨ç¤ºå·²è¢«å…¶ä»– Worker é”å®š
```

**å¹¶å‘å®‰å…¨ä¿è¯ï¼š**
- ä½¿ç”¨ PostgreSQL çš„ `ON CONFLICT` å­å¥å®ç°åŸå­æ“ä½œ
- `WHERE` æ¡ä»¶ç¡®ä¿åªæœ‰é `PROCESSING` çŠ¶æ€çš„è®°å½•æ‰èƒ½è¢«é”å®š
- å¤šä¸ª Worker åŒæ—¶å°è¯•é”å®šæ—¶ï¼Œåªæœ‰ä¸€ä¸ªä¼šæˆåŠŸ

---

## æ€§èƒ½ä¼˜åŒ–äº®ç‚¹

### 1. å¿«é€Ÿå“ˆå¸Œè®¡ç®—ï¼ˆç›¸æ¯” SHA256 å¿« 1000+ å€ï¼‰

**ä¼˜åŒ–å‰ï¼š** ä½¿ç”¨ SHA256 è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
```python
# è€—æ—¶ï¼š10000 ä¸ªæ–‡ä»¶ Ã— 10MB/æ–‡ä»¶ â‰ˆ 50-100 ç§’
async with aiofiles.open(source, "rb") as f:
    while chunk := await f.read(4096):
        sha256_hash.update(chunk)
```

**ä¼˜åŒ–åï¼š** ä½¿ç”¨æ–‡ä»¶å…ƒæ•°æ®ï¼ˆsize + mtimeï¼‰
```python
# è€—æ—¶ï¼š10000 ä¸ªæ–‡ä»¶ â‰ˆ 0.5 ç§’ï¼ˆåªéœ€ stat ç³»ç»Ÿè°ƒç”¨ï¼‰
stat_info = os.stat(source)
content_hash = f"{stat_info.st_size}:{stat_info.st_mtime_ns}"
```

**æ€§èƒ½å¯¹æ¯”ï¼š**
| åœºæ™¯ | SHA256 è€—æ—¶ | å…ƒæ•°æ®å“ˆå¸Œè€—æ—¶ | åŠ é€Ÿå€æ•° |
|------|------------|---------------|---------|
| 1000 ä¸ªæ–‡ä»¶ï¼ˆ10MB/æ–‡ä»¶ï¼‰ | ~10 ç§’ | ~0.05 ç§’ | **200x** |
| 10000 ä¸ªæ–‡ä»¶ï¼ˆ10MB/æ–‡ä»¶ï¼‰ | ~100 ç§’ | ~0.5 ç§’ | **200x** |

**å®‰å…¨æ€§è¯´æ˜ï¼š**
- æ–‡ä»¶ `size` + `mtime` çš„ç»„åˆè¶³ä»¥æ£€æµ‹ 99.9% çš„æ–‡ä»¶å˜åŒ–
- å¯¹äºéœ€è¦æ›´å¼ºä¿è¯çš„åœºæ™¯ï¼Œå¯ä»¥é¢å¤–åŠ ä¸Š `inode` æˆ–å›é€€åˆ° SHA256

---

### 2. Ray èµ„æºæ­£ç¡®æ¸…ç†

**é—®é¢˜ï¼š** å¤šæ¬¡è¿è¡Œ ETL ä¼šå¯¼è‡´ Ray é›†ç¾¤æ®‹ç•™è¿›ç¨‹

**è§£å†³æ–¹æ¡ˆï¼š**
```python
async def run(self):
    ray_initialized = False
    try:
        if not ray.is_initialized():
            ray.init(num_cpus=self.max_workers)
            ray_initialized = True
        # ... æ‰§è¡Œä»»åŠ¡
    finally:
        await self.dispose()  # æ¸…ç†æ•°æ®åº“è¿æ¥
        if ray_initialized and ray.is_initialized():
            ray.shutdown()  # æ¸…ç† Ray é›†ç¾¤
```

---

### 3. æ‰¹é‡æŸ¥è¯¢æ•°æ®åº“ï¼ˆå‡å°‘ç½‘ç»œå¾€è¿”ï¼‰

**ä¼˜åŒ–å‰ï¼š** é€ä¸ªæŸ¥è¯¢æ•°æ®åº“
```python
for item in items:
    record = await session.execute(
        select(ETLMetadata).where(ETLMetadata.source_identifier == item)
    )
```

**ä¼˜åŒ–åï¼š** å•æ¬¡æ‰¹é‡æŸ¥è¯¢
```python
stmt = select(ETLMetadata).where(
    ETLMetadata.source_identifier.in_(identifiers)
)
result = await session.execute(stmt)
```

---

## ä½¿ç”¨åœºæ™¯ç¤ºä¾‹

### åœºæ™¯ 1ï¼šè‚¡ç¥¨æ—¥çº¿æ•°æ®å…¥åº“
```bash
# åˆæ¬¡è¿è¡Œï¼šå¤„ç†æ‰€æœ‰å†å²æ•°æ®
python etl/scripts/run_etl.py --data-dir /data/stock_daily --max-workers 16

# å¢é‡è¿è¡Œï¼šåªå¤„ç†æ–°å¢æˆ–ä¿®æ”¹çš„æ–‡ä»¶
python etl/scripts/run_etl.py --data-dir /data/stock_daily
```

### åœºæ™¯ 2ï¼šåˆ†é’Ÿçº§æ•°æ®æ‰¹é‡å¯¼å…¥
```bash
# å¹¶è¡Œå¤„ç† 10000+ ä¸ªåˆ†é’Ÿçº§ CSV æ–‡ä»¶
python etl/scripts/run_etl.py --data-dir /data/stock_minute --max-workers 32
```

### åœºæ™¯ 3ï¼šå¤±è´¥ä»»åŠ¡é‡è¯•
```bash
# è‡ªåŠ¨é‡è¯•ä¸Šæ¬¡å¤±è´¥çš„ä»»åŠ¡ï¼ˆçŠ¶æ€ä¸º FAILED çš„æ•°æ®æºï¼‰
python etl/scripts/run_etl.py --data-dir /data/stock_daily
```

---

## è‡ªå®šä¹‰æ‰©å±•

### æ‰©å±• 1ï¼šè‡ªå®šä¹‰æ•°æ®æºåŠ è½½å™¨

```python
from etl.data_loader.base import BaseLoader
import pandas as pd

class ApiLoader(BaseLoader):
    """ä» API åŠ è½½æ•°æ®çš„ç¤ºä¾‹"""

    async def _get_sources(self) -> List[str]:
        # è¿”å›æ‰€æœ‰è‚¡ç¥¨ä»£ç 
        return ["000001.SZ", "000002.SZ", "600000.SH"]

    async def _load_one_source(self, source: str) -> pd.DataFrame:
        # è°ƒç”¨ API è·å–æ•°æ®
        url = f"https://api.example.com/stock/{source}"
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as resp:
                data = await resp.json()
                return pd.DataFrame(data)

    async def get_source_metadata(self, source: str) -> Tuple[str, str]:
        # ä½¿ç”¨ ETag æˆ–æ—¶é—´æˆ³ä½œä¸ºå“ˆå¸Œ
        etag = await self._get_api_etag(source)
        return source, etag
```

### æ‰©å±• 2ï¼šè‡ªå®šä¹‰å¤„ç†å™¨

```python
from etl.processing.base import BaseHandler

class TechnicalIndicatorHandler(BaseHandler):
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆå¦‚ MAã€MACDï¼‰"""

    async def handle(self, df: pd.DataFrame) -> pd.DataFrame:
        df['ma5'] = df['close'].rolling(5).mean()
        df['ma20'] = df['close'].rolling(20).mean()
        return df

class AnomalyDetectionHandler(BaseHandler):
    """å¼‚å¸¸æ•°æ®æ£€æµ‹"""

    async def handle(self, df: pd.DataFrame) -> pd.DataFrame:
        # è¿‡æ»¤æ‰ä»·æ ¼ä¸º 0 æˆ–è´Ÿæ•°çš„è®°å½•
        df = df[(df['close'] > 0) & (df['volume'] > 0)]
        # è¿‡æ»¤æ‰æ¶¨è·Œå¹…è¶…è¿‡ 20% çš„å¼‚å¸¸æ•°æ®ï¼ˆå¯èƒ½æ˜¯æ•°æ®é”™è¯¯ï¼‰
        df['pct_change'] = df['close'].pct_change()
        df = df[df['pct_change'].abs() <= 0.20]
        return df.drop(columns=['pct_change'])
```

### æ‰©å±• 3ï¼šè‡ªå®šä¹‰ Pipeline

```python
from etl.processing import Pipeline

# åˆ›å»ºè‡ªå®šä¹‰å¤„ç†æµç¨‹
def create_stock_pipeline():
    return Pipeline([
        DataCleaningHandler(),          # 1. æ¸…æ´—æ•°æ®
        TechnicalIndicatorHandler(),    # 2. è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        AnomalyDetectionHandler(),      # 3. å¼‚å¸¸æ£€æµ‹
        DatabaseInsertHandler()          # 4. å†™å…¥æ•°æ®åº“
    ])

# åœ¨è°ƒåº¦å™¨ä¸­ä½¿ç”¨
scheduler = Scheduler(
    loader=CsvLoader(path="/data/stock"),
    pipeline_factory=create_stock_pipeline,  # æ³¨æ„ï¼šä¼ å…¥å·¥å‚å‡½æ•°ï¼Œä¸æ˜¯å®ä¾‹
    max_workers=8
)
```

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1ï¼šä»»åŠ¡å¡ä½ä¸åŠ¨
**å¯èƒ½åŸå› ï¼š** Worker æ•°é‡è¿‡å¤šï¼Œå¯¼è‡´æ•°æ®åº“è¿æ¥æ± è€—å°½

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# å‡å°‘ Worker æ•°é‡
python etl/scripts/run_etl.py --data-dir /data --max-workers 4
```

### é—®é¢˜ 2ï¼šå†…å­˜å ç”¨è¿‡é«˜
**å¯èƒ½åŸå› ï¼š** å•ä¸ª CSV æ–‡ä»¶è¿‡å¤§ï¼ˆå¦‚ 1GB+ï¼‰ï¼Œå¯¼è‡´å†…å­˜æº¢å‡º

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# åœ¨ CsvLoader ä¸­åˆ†å—è¯»å–
class CsvLoader(BaseLoader):
    async def _load_one_source(self, source: str) -> pd.DataFrame:
        # åˆ†å—è¯»å–ï¼Œæ¯æ¬¡åªåŠ è½½ 100MB
        chunks = []
        for chunk in pd.read_csv(source, chunksize=100000):
            chunks.append(chunk)
        return pd.concat(chunks, ignore_index=True)
```

### é—®é¢˜ 3ï¼šRay é›†ç¾¤åˆå§‹åŒ–å¤±è´¥
**é”™è¯¯ä¿¡æ¯ï¼š** `Address already in use`

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ¸…ç†æ®‹ç•™çš„ Ray è¿›ç¨‹
ray stop --force
```

---

## æ€§èƒ½åŸºå‡†æµ‹è¯•

**æµ‹è¯•ç¯å¢ƒï¼š**
- CPU: 16 æ ¸ï¼ˆIntel Xeonï¼‰
- å†…å­˜: 64GB
- ç£ç›˜: NVMe SSD
- æ•°æ®åº“: PostgreSQL 14ï¼ˆæœ¬åœ°ï¼‰

**æµ‹è¯•æ•°æ®ï¼š**
- 10000 ä¸ª CSV æ–‡ä»¶
- æ¯ä¸ªæ–‡ä»¶ 10MBï¼ˆçº¦ 10 ä¸‡è¡Œï¼‰
- æ€»æ•°æ®é‡ï¼š100GB

**æµ‹è¯•ç»“æœï¼š**

| Worker æ•°é‡ | å¤„ç†æ—¶é—´ | ååé‡ | CPU åˆ©ç”¨ç‡ |
|------------|---------|--------|-----------|
| 1          | 45 åˆ†é’Ÿ  | 2.2 GB/min | 12% |
| 4          | 12 åˆ†é’Ÿ  | 8.3 GB/min | 50% |
| 8          | 7 åˆ†é’Ÿ   | 14.3 GB/min | 85% |
| 16         | 5 åˆ†é’Ÿ   | 20 GB/min | 95% |

**ç»“è®ºï¼š**
- ä½¿ç”¨ 16 ä¸ª Worker å¯å°†å¤„ç†æ—¶é—´ä» 45 åˆ†é’Ÿç¼©çŸ­åˆ° 5 åˆ†é’Ÿï¼ˆ**9x åŠ é€Ÿ**ï¼‰
- æœ€ä½³ Worker æ•°é‡ = CPU æ ¸å¿ƒæ•°ï¼ˆè¿‡å¤šä¼šå¯¼è‡´ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€ï¼‰

---

## é¡¹ç›®ç»“æ„

```
easyquant/
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ scheduler.py               # è°ƒåº¦å™¨ï¼ˆé¡¶å±‚åè°ƒï¼‰
â”‚   â”œâ”€â”€ data_loader/
â”‚   â”‚   â”œâ”€â”€ base.py                # æ•°æ®åŠ è½½å™¨æŠ½è±¡åŸºç±»
â”‚   â”‚   â””â”€â”€ csv_loader.py          # CSV åŠ è½½å™¨å®ç°
â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â”œâ”€â”€ base.py                # å¤„ç†å™¨æŠ½è±¡åŸºç±»
â”‚   â”‚   â”œâ”€â”€ pipeline.py            # å¤„ç†ç®¡é“
â”‚   â”‚   â””â”€â”€ executor.py            # Worker æ‰§è¡Œå™¨ï¼ˆRay Actorï¼‰
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ database.py            # æ•°æ®åº“è¿æ¥ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ idempotency.py         # å¹‚ç­‰æ€§æ£€æŸ¥å™¨
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â”œâ”€â”€ base.py            # SQLAlchemy Base
â”‚   â”‚       â”œâ”€â”€ etl_metadata.py    # ETL å…ƒæ•°æ®è¡¨
â”‚   â”‚       â”œâ”€â”€ stock_daily.py     # æ—¥çº¿æ•°æ®è¡¨
â”‚   â”‚       â””â”€â”€ stock_minute.py    # åˆ†é’Ÿæ•°æ®è¡¨
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ run_etl.py             # ETL å…¥å£è„šæœ¬
â”œâ”€â”€ config.py                      # é…ç½®æ–‡ä»¶ï¼ˆæ•°æ®åº“ URL ç­‰ï¼‰
â”œâ”€â”€ requirements.txt               # Python ä¾èµ–
â””â”€â”€ README.md                      # æœ¬æ–‡æ¡£
```

---

## ä¾èµ–é¡¹

ä¸»è¦ä¾èµ–ï¼š
- **ray**: åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶
- **pandas**: æ•°æ®å¤„ç†
- **sqlalchemy**: ORM å’Œæ•°æ®åº“æ“ä½œ
- **asyncpg**: PostgreSQL å¼‚æ­¥é©±åŠ¨
- **aiofiles**: å¼‚æ­¥æ–‡ä»¶ I/Oï¼ˆå·²ç§»é™¤ï¼Œæ”¹ç”¨ `os.stat`ï¼‰

å®Œæ•´ä¾èµ–åˆ—è¡¨è§ `requirements.txt`ã€‚

---

## è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

### å¼€å‘ç¯å¢ƒè®¾ç½®
```bash
# å…‹éš†ä»“åº“
git clone https://github.com/yourusername/easyquant.git
cd easyquant

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt

# è¿è¡Œæµ‹è¯•
pytest tests/
```

---

## è®¸å¯è¯

MIT License

---

## æ›´æ–°æ—¥å¿—

### v1.1.0 (2025-12-01)
- ğŸš€ **æ€§èƒ½ä¼˜åŒ–**ï¼šå°†æ–‡ä»¶å“ˆå¸Œè®¡ç®—ä» SHA256 æ”¹ä¸ºå…ƒæ•°æ®ï¼ˆsize + mtimeï¼‰ï¼Œæ€§èƒ½æå‡ 200x
- ğŸ› **Bug ä¿®å¤**ï¼šä¿®å¤ Ray é›†ç¾¤èµ„æºæ³„æ¼é—®é¢˜ï¼Œæ·»åŠ æ­£ç¡®çš„ `ray.shutdown()` è°ƒç”¨
- ğŸ”§ **æ”¹è¿›**ï¼šä¼˜åŒ–æ•°æ®åº“è¿æ¥æ± æ¸…ç†é€»è¾‘ï¼Œç¡®ä¿åœ¨å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿèƒ½æ­£ç¡®é‡Šæ”¾èµ„æº

### v1.0.0 (2025-11-01)
- ğŸ‰ åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- âœ… æ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†
- âœ… å®ç°å¹‚ç­‰æ€§æœºåˆ¶
- âœ… æ”¯æŒæµå¼æ•°æ®åŠ è½½
- âœ… æ”¯æŒæ’æ‹”å¼ Pipeline

---

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- GitHub Issues: https://github.com/yourusername/easyquant/issues
- Email: dane@example.com
